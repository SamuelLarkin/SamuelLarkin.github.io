########################################
# 2025
########################################

@article{PINE2025101723,
  title = {Speech Generation for Indigenous Language Education},
  journal = {Computer Speech & Language},
  volume = {90},
  pages = {101723},
  year = {2025},
  issn = {0885-2308},
  doi = {https://doi.org/10.1016/j.csl.2024.101723},
  url = {https://www.sciencedirect.com/science/article/pii/S0885230824001062},
  author = {Aidan Pine and Erica Cooper and David Guzmán and Eric Joanis and Anna Kazantseva and Ross Krekoski and Roland Kuhn and Samuel Larkin and Patrick Littell and Delaney Lothian and Akwiratékha’ Martin and Korin Richmond and Marc Tessier and Cassia Valentini-Botinhao and Dan Wells and Junichi Yamagishi},
  keywords = {Speech synthesis, Text-to-speech, Low-resource languages, Indigenous languages, Language education, Language revitalization},
  abstract = {As the quality of contemporary speech synthesis improves, so too does the interest from language communities in developing text-to-speech (TTS) systems for a variety of real-world applications. Much of the work on TTS has focused on high-resource languages, resulting in implicitly resource-intensive paths to building such systems. The goal of this paper is to provide signposts and points of reference for future low-resource speech synthesis efforts, with insights drawn from the Speech Generation for Indigenous Language Education (SGILE) project. Funded and coordinated by the National Research Council of Canada (NRC), this multi-year, multi-partner project has the goal of producing high-quality text-to-speech systems that support the teaching of Indigenous languages in a variety of educational contexts. We provide background information and motivation for the project, as well as details about our approach and project structure, including results from a multi-day requirements-gathering session. We discuss some of our key challenges, including building models with appropriate controls for educators, improving model data efficiency, and strategies for low-resource transfer learning and evaluation. Finally, we provide a detailed survey of existing speech synthesis software and introduce EveryVoice TTS, a toolkit designed specifically for low-resource speech synthesis.}
}

@inproceedings{chikati-etal-2025-challenges,
  title = "Challenges in Technical Regulatory Text Variation Detection",
  author = "Chikati, Shriya Vaagdevi  and
    Larkin, Samuel  and
    Minicola, David  and
    Lo, Chi-kiu",
  editor = "Gokhan, Tuba  and
    Wang, Kexin  and
    Gurevych, Iryna  and
    Briscoe, Ted",
  booktitle = "Proceedings of the 1st Regulatory NLP Workshop (RegNLP 2025)",
  month = jan,
  year = "2025",
  address = "Abu Dhabi, UAE",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2025.regnlp-1.2/",
  pages = "5--9",
  abstract = "We present a preliminary study on the feasibility of using current natural language processing techniques to detect variations between the construction codes of different jurisdictions. We formulate the task as a sentence alignment problem and evaluate various sentence representation models for their performance in this task. Our results show that task-specific trained embeddings perform marginally better than other models, but the overall accuracy remains a challenge. We also show that domain-specific fine-tuning hurts the task performance. The results highlight the challenges of developing NLP applications for technical regulatory texts."
}

########################################
# 2024
########################################

MSLC24: Further Challenges for Metrics on a Wide Landscape of Translation Quality Technical
https://github.com/nrc-cnrc/MSLC
Report for HoC 2024 about Continual Learning

@inproceedings{knowles-etal-2024-tradeoffs,
  title = "Some Tradeoffs in Continual Learning for Parliamentary Neural Machine Translation Systems",
  author = "Knowles, Rebecca  and
    Larkin, Samuel  and
    Simard, Michel  and
    Tessier, Marc A  and
    Bernier-Colborne, Gabriel  and
    Goutte, Cyril  and
    Lo, Chi-kiu",
  editor = "Knowles, Rebecca  and
    Eriguchi, Akiko  and
    Goel, Shivali",
  booktitle = "Proceedings of the 16th Conference of the Association for Machine Translation in the Americas (Volume 1: Research Track)",
  month = sep,
  year = "2024",
  address = "Chicago, USA",
  publisher = "Association for Machine Translation in the Americas",
  url = "https://aclanthology.org/2024.amta-research.10/",
  pages = "102--118",
  abstract = "In long-term translation projects, like Parliamentary text, there is a desire to build machine translation systems that can adapt to changes over time. We implement and examine a simple approach to continual learning for neural machine translation, exploring tradeoffs between consistency, the model`s ability to learn from incoming data, and the time a client would need to wait to obtain a newly trained translation system."
}

@inproceedings{knowles-etal-2024-mslc24,
  title = "{MSLC}24: Further Challenges for Metrics on a Wide Landscape of Translation Quality",
  author = "Knowles, Rebecca  and
    Larkin, Samuel  and
    Lo, Chi-Kiu",
  editor = "Haddow, Barry  and
    Kocmi, Tom  and
    Koehn, Philipp  and
    Monz, Christof",
  booktitle = "Proceedings of the Ninth Conference on Machine Translation",
  month = nov,
  year = "2024",
  address = "Miami, Florida, USA",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2024.wmt-1.34/",
  doi = "10.18653/v1/2024.wmt-1.34",
  pages = "475--491",
  abstract = "In this second edition of the Metric Score Landscape Challenge (MSLC), we examine how automatic metrics for machine translation perform on a wide variety of machine translation output, ranging from very low quality systems to the types of high-quality systems submitted to the General MT shared task at WMT. We also explore metric results on specific types of data, such as empty strings, wrong- or mixed-language text, and more. We raise several alarms about inconsistencies in metric scores, some of which can be resolved by increasingly explicit instructions for metric use, while others highlight technical flaws."
}

Possibly Challenges in Technical Regulatory Text Variation Detection with Jackie and Shriya

@inproceedings{larkin-etal-2024-MSLC24,
  title = "MSLC24 Submissions to the General Machine Translation Task",
  author = "Larkin, Samuel  and
    Lo, Chi-kiu  and
    Knowles, Rebecca",
  editor = "",
  booktitle = "Proceedings of the Ninth Conference on Machine Translation",
  month = dec,
  year = "2024",
  address = "",
  publisher = "Association for Computational Linguistics",
  url = "",
  doi = "",
  pages = "",
}

% ??SGILE & EveryVoice 2024???
% https://www.sciencedirect.com/science/article/pii/S0885230824001062
% https://doi.org/10.1016/j.csl.2024.101723

@article{PINE2024101723,
  title = {Speech Generation for Indigenous Language Education},
  journal = {Computer Speech & Language},
  pages = {101723},
  year = {2024},
  issn = {0885-2308},
  doi = {https://doi.org/10.1016/j.csl.2024.101723},
  url = {https://www.sciencedirect.com/science/article/pii/S0885230824001062},
  author = {Aidan Pine and Erica Cooper and David Guzmán and Eric Joanis and Anna Kazantseva and Ross Krekoski and Roland Kuhn and Samuel Larkin and Patrick Littell and Delaney Lothian and Akwiratékha’ Martin and Korin Richmond and Marc Tessier and Cassia Valentini-Botinhao and Dan Wells and Junichi Yamagishi},
  keywords = {Speech synthesis, Text-to-speech, Low-resource languages, Indigenous languages, Language education, Language revitalization},
  abstract = {As the quality of contemporary speech synthesis improves, so too does the interest from language communities in developing text-to-speech (TTS) systems for a variety of real-world applications. Much of the work on TTS has focused on high-resource languages, resulting in implicitly resource-intensive paths to building such systems. The goal of this paper is to provide signposts and points of reference for future low-resource speech synthesis efforts, with insights drawn from the Speech Generation for Indigenous Language Education (SGILE) project. Funded and coordinated by the National Research Council of Canada (NRC), this multi-year, multi-partner project has the goal of producing high-quality text-to-speech systems that support the teaching of Indigenous languages in a variety of educational contexts. We provide background information and motivation for the project, as well as details about our approach and project structure, including results from a multi-day requirements-gathering session. We discuss some of our key challenges, including building models with appropriate controls for educators, improving model data efficiency, and strategies for low-resource transfer learning and evaluation. Finally, we provide a detailed survey of existing speech synthesis software and introduce EveryVoice TTS, a toolkit designed specifically for low-resource speech synthesis.}
}

########################################
# 2023
########################################

@inproceedings{knowles-larkin-2023-long,
  title = "Long to reign over us: A Case Study of Machine Translation and a New Monarch",
  author = "Knowles, Rebecca  and
    Larkin, Samuel",
  editor = "Rogers, Anna  and
    Boyd-Graber, Jordan  and
    Okazaki, Naoaki",
  booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
  month = jul,
  year = "2023",
  address = "Toronto, Canada",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2023.findings-acl.412",
  doi = "10.18653/v1/2023.findings-acl.412",
  pages = "6589--6598",
  abstract = "Novel terminology and changes in terminology are often a challenge for machine translation systems. The passing of Queen Elizabeth II and the accession of King Charles III provide a striking example of translation shift in the real world, particularly in translation contexts that have ambiguity. Examining translation between French and English, we present a focused case-study of translations about King Charles III as produced both by publicly-available MT systems and by a neural machine translation system trained specifically on Canadian parliamentary text. We find that even in cases where human translators would have adequate context to disambiguate terms from the source language, machine translation systems do not always produce the expected output. Where we are able to analyze the training data, we note that this may represent artifacts in the data, raising important questions about machine translation updates in light of real world events.",
}

@inproceedings{lo-etal-2023-metric,
  title = "Metric Score Landscape Challenge ({MSLC}23): Understanding Metrics{'} Performance on a Wider Landscape of Translation Quality",
  author = "Lo, Chi-kiu  and
    Larkin, Samuel  and
    Knowles, Rebecca",
  editor = "Koehn, Philipp  and
    Haddow, Barry  and
    Kocmi, Tom  and
    Monz, Christof",
  booktitle = "Proceedings of the Eighth Conference on Machine Translation",
  month = dec,
  year = "2023",
  address = "Singapore",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2023.wmt-1.65",
  doi = "10.18653/v1/2023.wmt-1.65",
  pages = "776--799",
  abstract = "The Metric Score Landscape Challenge (MSLC23) dataset aims to gain insight into metric scores on a broader/wider landscape of machine translation (MT) quality. It provides a collection of low- to medium-quality MT output on the WMT23 general task test set. Together with the high quality systems submitted to the general task, this will enable better interpretation of metric scores across a range of different levels of translation quality. With this wider range of MT quality, we also visualize and analyze metric characteristics beyond just correlation.",
}

@inproceedings{knowles-etal-2023-terminology,
  title = "Terminology in Neural Machine Translation: A Case Study of the {C}anadian {H}ansard",
  author = "Knowles, Rebecca  and
    Larkin, Samuel  and
    Tessier, Marc  and
    Simard, Michel",
  editor = "Nurminen, Mary  and
    Brenner, Judith  and
    Koponen, Maarit  and
    Latomaa, Sirkku  and
    Mikhailov, Mikhail  and
    Schierl, Frederike  and
    Ranasinghe, Tharindu  and
    Vanmassenhove, Eva  and
    Vidal, Sergi Alvarez  and
    Aranberri, Nora  and
    Nunziatini, Mara  and
    Escart{\'\i}n, Carla Parra  and
    Forcada, Mikel  and
    Popovic, Maja  and
    Scarton, Carolina  and
    Moniz, Helena",
  booktitle = "Proceedings of the 24th Annual Conference of the European Association for Machine Translation",
  month = jun,
  year = "2023",
  address = "Tampere, Finland",
  publisher = "European Association for Machine Translation",
  url = "https://aclanthology.org/2023.eamt-1.47",
  pages = "481--488",
  abstract = "Incorporating terminology into a neural machine translation (NMT) system is a feature of interest for many users of machine translation. In this case study of English-French Canadian Parliamentary text, we examine the performance of standard NMT systems at handling terminology and consider the tradeoffs between potential performance improvements and the efforts required to maintain terminological resources specifically for NMT.",
}

########################################
# 2021
########################################

@inproceedings{knowles-etal-2021-nrc,
  title        = {{NRC}-{CNRC} Machine Translation Systems for the 2021 {A}mericas{NLP} Shared Task},
  author       = {Knowles, Rebecca  and Stewart, Darlene  and Larkin, Samuel  and Littell, Patrick},
  year         = 2021,
  month        = jun,
  booktitle    = {Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the Americas},
  publisher    = {Association for Computational Linguistics},
  address      = {Online},
  pages        = {224--233},
  doi          = {10.18653/v1/2021.americasnlp-1.25},
  url          = {https://aclanthology.org/2021.americasnlp-1.25},
  abstract     = {We describe the NRC-CNRC systems submitted to the AmericasNLP shared task on machine translation. We submitted systems translating from Spanish into Wix{\'a}rika, Nahuatl, Rar{\'a}muri, and Guaran{\'\i}. Our best neural machine translation systems used multilingual pretraining, ensembling, finetuning, training on parts of the development data, and subword regularization. We also submitted translation memory systems as a strong baseline.}
}

@inproceedings{larkin-etal-2021-like,
  title        = {Like Chalk and Cheese? On the Effects of Translationese in {MT} Training},
  author       = {Larkin, Samuel  and Simard, Michel  and Knowles, Rebecca},
  year         = 2021,
  month        = aug,
  booktitle    = {Proceedings of Machine Translation Summit XVIII: Research Track},
  publisher    = {Association for Machine Translation in the Americas},
  address      = {Virtual},
  pages        = {103--113},
  url          = {https://aclanthology.org/2021.mtsummit-research.9},
  abstract     = {We revisit the topic of translation direction in the data used for training neural machine translation systems and focusing on a real-world scenario with known translation direction and imbalances in translation direction: the Canadian Hansard. According to automatic metrics and we observe that using parallel data that was produced in the {``}matching{''} translation direction (Authentic source and translationese target) improves translation quality. In cases of data imbalance in terms of translation direction and we find that tagging of translation direction can close the performance gap. We perform a human evaluation that differs slightly from the automatic metrics and but nevertheless confirms that for this French-English dataset that is known to contain high-quality translations and authentic or tagged mixed source improves over translationese source for training.}
}

@inproceedings{knowles-larkin-2021-nrc,
  title        = {{NRC}-{CNRC} Systems for {U}pper {S}orbian-{G}erman and {L}ower {S}orbian-{G}erman Machine Translation 2021},
  author       = {Knowles, Rebecca  and Larkin, Samuel},
  year         = 2021,
  month        = nov,
  booktitle    = {Proceedings of the Sixth Conference on Machine Translation},
  publisher    = {Association for Computational Linguistics},
  address      = {Online},
  pages        = {999--1008},
  url          = {https://aclanthology.org/2021.wmt-1.107},
  abstract     = {We describe our neural machine translation systems for the 2021 shared task on Unsupervised and Very Low Resource Supervised MT, translating between Upper Sorbian and German (low-resource) and between Lower Sorbian and German (unsupervised). The systems incorporated data filtering, backtranslation, BPE-dropout, ensembling, and transfer learning from high(er)-resource languages. As measured by automatic metrics, our systems showed strong performance, consistently placing first or tied for first across most metrics and translation directions.}
}

########################################
# 2020
########################################

@inproceedings{joanis-etal-2020-nunavut,
  title        = {The {N}unavut {H}ansard {I}nuktitut{--}{E}nglish Parallel Corpus 3.0 with Preliminary Machine Translation Results},
  author       = {Joanis, Eric  and Knowles, Rebecca  and Kuhn, Roland  and Larkin, Samuel  and Littell, Patrick  and Lo, Chi-kiu  and Stewart, Darlene  and Micher, Jeffrey},
  year         = 2020,
  month        = may,
  booktitle    = {Proceedings of the 12th Language Resources and Evaluation Conference},
  publisher    = {European Language Resources Association},
  address      = {Marseille, France},
  pages        = {2562--2572},
  isbn         = {979-10-95546-34-4},
  url          = {https://aclanthology.org/2020.lrec-1.312},
  abstract     = {The Inuktitut language, a member of the Inuit-Yupik-Unangan language family, is spoken across Arctic Canada and noted for its morphological complexity. It is an official language of two territories, Nunavut and the Northwest Territories, and has recognition in additional regions. This paper describes a newly released sentence-aligned Inuktitut{--}English corpus based on the proceedings of the Legislative Assembly of Nunavut, covering sessions from April 1999 to June 2017. With approximately 1.3 million aligned sentence pairs, this is, to our knowledge, the largest parallel corpus of a polysynthetic language or an Indigenous language of the Americas released to date. The paper describes the alignment methodology used, the evaluation of the alignments, and preliminary experiments on statistical and neural machine translation (SMT and NMT) between Inuktitut and English, in both directions.},
  language     = {English}
}

@inproceedings{lo-larkin-2020-machine,
  title        = {Machine Translation Reference-less Evaluation using {Y}i{S}i-2 with Bilingual Mappings of Massive Multilingual Language Model},
  author       = {Lo, Chi-kiu  and Larkin, Samuel},
  year         = 2020,
  month        = nov,
  booktitle    = {Proceedings of the Fifth Conference on Machine Translation},
  publisher    = {Association for Computational Linguistics},
  address      = {Online},
  pages        = {903--910},
  url          = {https://aclanthology.org/2020.wmt-1.100},
  abstract     = {We present a study on using YiSi-2 with massive multilingual pretrained language models for machine translation (MT) reference-less evaluation. Aiming at finding better semantic representation for semantic MT evaluation, we first test YiSi-2 with contextual embed- dings extracted from different layers of two different pretrained models, multilingual BERT and XLM-RoBERTa. We also experiment with learning bilingual mappings that trans- form the vector subspace of the source language to be closer to that of the target language in the pretrained model to obtain more accurate cross-lingual semantic similarity representations. Our results show that YiSi-2{'}s correlation with human direct assessment on translation quality is greatly improved by replacing multilingual BERT with XLM-RoBERTa and projecting the source embeddings into the tar- get embedding space using a cross-lingual lin- ear projection (CLP) matrix learnt from a small development set.}
}

@inproceedings{knowles-etal-2020-nrc-systems,
  title        = {{NRC} Systems for Low Resource {G}erman-{U}pper {S}orbian Machine Translation 2020: Transfer Learning with Lexical Modifications},
  author       = {Knowles, Rebecca  and Larkin, Samuel  and Stewart, Darlene  and Littell, Patrick},
  year         = 2020,
  month        = nov,
  booktitle    = {Proceedings of the Fifth Conference on Machine Translation},
  publisher    = {Association for Computational Linguistics},
  address      = {Online},
  pages        = {1112--1122},
  url          = {https://aclanthology.org/2020.wmt-1.132},
  abstract     = {We describe the National Research Council of Canada (NRC) neural machine translation systems for the German-Upper Sorbian supervised track of the 2020 shared task on Unsupervised MT and Very Low Resource Supervised MT. Our models are ensembles of Transformer models, built using combinations of BPE-dropout, lexical modifications, and backtranslation.}
}

@inproceedings{knowles-etal-2020-nrc,
  title        = {{NRC} Systems for the 2020 {I}nuktitut-{E}nglish News Translation Task},
  author       = {Knowles, Rebecca  and Stewart, Darlene  and Larkin, Samuel  and Littell, Patrick},
  year         = 2020,
  month        = nov,
  booktitle    = {Proceedings of the Fifth Conference on Machine Translation},
  publisher    = {Association for Computational Linguistics},
  address      = {Online},
  pages        = {156--170},
  url          = {https://aclanthology.org/2020.wmt-1.13},
  abstract     = {We describe the National Research Council of Canada (NRC) submissions for the 2020 Inuktitut-English shared task on news translation at the Fifth Conference on Machine Translation (WMT20). Our submissions consist of ensembled domain-specific finetuned transformer models, trained using the Nunavut Hansard and news data and, in the case of Inuktitut-English, backtranslated news and parliamentary data. In this work we explore challenges related to the relatively small amount of parallel data, morphological complexity, and domain shifts.}
}

########################################
# 2019
########################################

@inproceedings{littell-etal-2019-multi,
  title        = {Multi-Source Transformer for {K}azakh-{R}ussian-{E}nglish Neural Machine Translation},
  author       = {Littell, Patrick  and Lo, Chi-kiu  and Larkin, Samuel  and Stewart, Darlene},
  year         = 2019,
  month        = aug,
  booktitle    = {Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)},
  publisher    = {Association for Computational Linguistics},
  address      = {Florence, Italy},
  pages        = {267--274},
  doi          = {10.18653/v1/W19-5326},
  url          = {https://aclanthology.org/W19-5326},
  abstract     = {We describe the neural machine translation (NMT) system developed at the National Research Council of Canada (NRC) for the Kazakh-English news translation task of the Fourth Conference on Machine Translation (WMT19). Our submission is a multi-source NMT taking both the original Kazakh sentence and its Russian translation as input for translating into English.}
}

@Misc{Cai2019,
  author={Cai, Yuanjing
    and Wang, Yunli
      and Larkin, Samuel
      and Goutte, Cyril},
  title={Bursty event detection on social media},
  year={2019},
  month={Aug},
  day={12},
  publisher={ACL Anthology (online)},
  abstract={Messages posted on social media such as Twitter and Instagram are a rich and promising source of information on real-life events. However, due to the high volume and the noisy nature of posts on social media, the messages reporting events are usually overwhelmed by unrelated daily chatter. To detect unspecified events, many topic modeling and wavelet signal processing methods have been proposed. In this paper, we propose an improved method, BCCED, using a burstiness index and co-occurrence clustering for event detection, that builds on the Event Detection with Clustering of Wavelet-based Signals (EDCoW) method of Weng et al. [2011]. We compare their performance with two topic modeling methods on two social media datasets. Experiments show that BCCED outperforms these alternatives for unspecified event detection from social media.},
  note={7 p.},
  note={Collection / Collection : NRC Publications Archive / Archives des publications du CNRC},
  note={Record identifier / Identificateur de l'enregistrement : 76d675b4-d734-4dfa-bd6a-8c05519e0c93},
  language={eng}
}

########################################
# 2018
########################################

@inproceedings{goutte-etal-2018-eurogames16,
  title        = {{E}uro{G}ames16: Evaluating Change Detection in Online Conversation},
  author       = {Goutte, Cyril  and Wang, Yunli  and Liao, Fangming  and Zanussi, Zachary  and Larkin, Samuel  and Grinberg, Yuri},
  year         = 2018,
  month        = may,
  booktitle    = {Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018)},
  publisher    = {European Language Resources Association (ELRA)},
  address      = {Miyazaki, Japan},
  url          = {https://aclanthology.org/L18-1277}
}

@inproceedings{littell-etal-2018-measuring,
  title        = {Measuring sentence parallelism using Mahalanobis distances: The {NRC} unsupervised submissions to the {WMT}18 Parallel Corpus Filtering shared task},
  author       = {Littell, Patrick  and Larkin, Samuel  and Stewart, Darlene  and Simard, Michel  and Goutte, Cyril  and Lo, Chi-kiu},
  year         = 2018,
  month        = oct,
  booktitle    = {Proceedings of the Third Conference on Machine Translation: Shared Task Papers},
  publisher    = {Association for Computational Linguistics},
  address      = {Belgium, Brussels},
  pages        = {900--907},
  doi          = {10.18653/v1/W18-6480},
  url          = {https://aclanthology.org/W18-6480},
  abstract     = {The WMT18 shared task on parallel corpus filtering (Koehn et al., 2018b) challenged teams to score sentence pairs from a large high-recall, low-precision web-scraped parallel corpus (Koehn et al., 2018a). Participants could use existing sample corpora (e.g. past WMT data) as a supervisory signal to learn what a {``}clean{''} corpus looks like. However, in lower-resource situations it often happens that the target corpus of the language is the \textit{only} sample of parallel text in that language. We therefore made several unsupervised entries, setting ourselves an additional constraint that we not utilize the additional clean parallel corpora. One such entry fairly consistently scored in the top ten systems in the 100M-word conditions, and for one task{---}translating the European Medicines Agency corpus (Tiedemann, 2009){---}scored among the best systems even in the 10M-word conditions.}
}

@inproceedings{lo-etal-2018-accurate,
  title        = {Accurate semantic textual similarity for cleaning noisy parallel corpora using semantic machine translation evaluation metric: The {NRC} supervised submissions to the Parallel Corpus Filtering task},
  author       = {Lo, Chi-kiu  and Simard, Michel  and Stewart, Darlene  and Larkin, Samuel  and Goutte, Cyril  and Littell, Patrick},
  year         = 2018,
  month        = oct,
  booktitle    = {Proceedings of the Third Conference on Machine Translation: Shared Task Papers},
  publisher    = {Association for Computational Linguistics},
  address      = {Belgium, Brussels},
  pages        = {908--916},
  doi          = {10.18653/v1/W18-6481},
  url          = {https://aclanthology.org/W18-6481},
  abstract     = {We present our semantic textual similarity approach in filtering a noisy web crawled parallel corpus using YiSi{---}a novel semantic machine translation evaluation metric. The systems mainly based on this supervised approach perform well in the WMT18 Parallel Corpus Filtering shared task (4th place in 100-million-word evaluation, 8th place in 10-million-word evaluation, and 6th place overall, out of 48 submissions). In fact, our best performing system{---}NRC-yisi-bicov is one of the only four submissions ranked top 10 in both evaluations. Our submitted systems also include some initial filtering steps for scaling down the size of the test corpus and a final redundancy removal step for better semantic and token coverage of the filtered corpus. In this paper, we also describe our unsuccessful attempt in automatically synthesizing a noisy parallel development corpus for tuning the weights to combine different parallelism and fluency features.}
}

########################################
# 2017
########################################

@inproceedings{chen-etal-2017-cost,
  title        = {Cost Weighting for Neural Machine Translation Domain Adaptation},
  author       = {Chen, Boxing  and Cherry, Colin  and Foster, George  and Larkin, Samuel},
  year         = 2017,
  month        = aug,
  booktitle    = {Proceedings of the First Workshop on Neural Machine Translation},
  publisher    = {Association for Computational Linguistics},
  address      = {Vancouver},
  pages        = {40--46},
  doi          = {10.18653/v1/W17-3205},
  url          = {https://aclanthology.org/W17-3205},
  abstract     = {In this paper, we propose a new domain adaptation technique for neural machine translation called cost weighting, which is appropriate for adaptation scenarios in which a small in-domain data set and a large general-domain data set are available. Cost weighting incorporates a domain classifier into the neural machine translation training algorithm, using features derived from the encoder representation in order to distinguish in-domain from out-of-domain data. Classifier probabilities are used to weight sentences according to their domain similarity when updating the parameters of the neural translation model. We compare cost weighting to two traditional domain adaptation techniques developed for statistical machine translation: data selection and sub-corpus weighting. Experiments on two large-data tasks show that both the traditional techniques and our novel proposal lead to significant gains, with cost weighting outperforming the traditional methods.}
}

@inproceedings{lo-etal-2017-nrc,
  title        = {{NRC} Machine Translation System for {WMT} 2017},
  author       = {Lo, Chi-kiu  and Chen, Boxing  and Cherry, Colin  and Foster, George  and Larkin, Samuel  and Stewart, Darlene  and Kuhn, Roland},
  year         = 2017,
  month        = sep,
  booktitle    = {Proceedings of the Second Conference on Machine Translation},
  publisher    = {Association for Computational Linguistics},
  address      = {Copenhagen, Denmark},
  pages        = {330--337},
  doi          = {10.18653/v1/W17-4732},
  url          = {https://aclanthology.org/W17-4732}
}

########################################
# 2013
########################################

@inproceedings{joanis-etal-2013-transferring,
  title        = {Transferring markup tags in statistical machine translation: a two-stream approach},
  author       = {Joanis, Eric  and Stewart, Darlene  and Larkin, Samuel  and Kuhn, Roland},
  year         = 2013,
  month        = sep # { 2},
  booktitle    = {Proceedings of the 2nd Workshop on Post-editing Technology and Practice},
  address      = {Nice, France},
  url          = {https://aclanthology.org/2013.mtsummit-wptp.9}
}

########################################
# 2012
########################################

@inproceedings{chen-etal-2012-port,
  title        = {{PORT}: a Precision-Order-Recall {MT} Evaluation Metric for Tuning},
  author       = {Chen, Boxing  and Kuhn, Roland  and Larkin, Samuel},
  year         = 2012,
  month        = jul,
  booktitle    = {Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  publisher    = {Association for Computational Linguistics},
  address      = {Jeju Island, Korea},
  pages        = {930--939},
  url          = {https://aclanthology.org/P12-1098}
}

########################################
# 2010
########################################

@inproceedings{larkin-etal-2010-lessons,
  title        = {Lessons from {NRC}{'}s Portage System at {WMT} 2010},
  author       = {Larkin, Samuel  and Chen, Boxing  and Foster, George  and Germann, Ulrich  and Joanis, Eric  and Johnson, Howard  and Kuhn, Roland},
  year         = 2010,
  month        = jul,
  booktitle    = {Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR}},
  publisher    = {Association for Computational Linguistics},
  address      = {Uppsala, Sweden},
  pages        = {127--132},
  url          = {https://aclanthology.org/W10-1717}
}

########################################
# 2009
########################################

@inproceedings{reddy-etal-2009-incorporating,
  title        = {Incorporating Knowledge of Source Language Text in a System for Dictation of Document Translations},
  author       = {Reddy, Aarthi  and Rose, Richard  and Safadi, Hani  and Larkin, Samuel  and Boulianne, Gilles},
  year         = 2009,
  month        = aug # { 26-30},
  booktitle    = {Proceedings of Machine Translation Summit XII: Papers},
  address      = {Ottawa, Canada},
  url          = {https://aclanthology.org/2009.mtsummit-papers.13}
}

@inproceedings{paul-etal-2009-portagelive,
  title        = {{P}ortage{L}ive: delivering machine translation technology via virtualization},
  author       = {Paul, Patrick  and Larkin, Samuel  and Germann, Ulrich  and Joanis, Eric  and Kuhn, Roland},
  year         = 2009,
  month        = aug # { 26-30},
  booktitle    = {Proceedings of Machine Translation Summit XII: Plenaries},
  address      = {Ottawa, Canada},
  url          = {https://aclanthology.org/2009.mtsummit-plenaries.15}
}

@misc{Foster09portagein,
  title        = {PORTAGE in the NIST 2009 MT Evaluation},
  author       = {George Foster and Boxing Chen and Eric Joanis and Howard Johnson and Samuel Larkin},
  year         = 2009
}

@inproceedings{germann-etal-2009-tightly,
  title        = {Tightly Packed Tries: How to Fit Large Models into Memory, and Make them Load Fast, Too},
  author       = {Germann, Ulrich  and Joanis, Eric  and Larkin, Samuel},
  year         = 2009,
  month        = jun,
  booktitle    = {Proceedings of the Workshop on Software Engineering, Testing, and Quality Assurance for Natural Language Processing ({SETQA}-{NLP} 2009)},
  publisher    = {Association for Computational Linguistics},
  address      = {Boulder, Colorado},
  pages        = {31--39},
  url          = {https://aclanthology.org/W09-1505}
}

########################################
# 2007
########################################

@unknown{unknown,
  title        = {Manageable Phrase-based Statistical Machine Translation Modelsâ€“with Pseudo-code and Proofs},
  author       = {Badr, Ghada and Joanis, Eric and Larkin, Samuel},
  year         = 2007,
  month        = {01},
  pages        = {}
}

@inproceedings{ueffing-etal-2007-nrcs,
  title        = {{NRC}{`}s {PORTAGE} System for {WMT} 2007},
  author       = {Ueffing, Nicola  and Simard, Michel  and Larkin, Samuel  and Johnson, Howard},
  year         = 2007,
  month        = jun,
  booktitle    = {Proceedings of the Second Workshop on Statistical Machine Translation},
  publisher    = {Association for Computational Linguistics},
  address      = {Prague, Czech Republic},
  pages        = {185--188},
  url          = {https://aclanthology.org/W07-0724}
}

########################################
# 2006
########################################

@article{article,
  title        = {PORTAGE Phrase-Based System for Chinese-to-English Translation},
  author       = {Kuhn, R. and Foster, G. and Larkin, Samuel and Ueffing, Nicola},
  year         = 2006,
  month        = {01},
  pages        = {}
}

@inproceedings{johnson-etal-2006-portage,
  title        = {{PORTAGE}: with Smoothed Phrase Tables and Segment Choice Models},
  author       = {Johnson, Howard  and Sadat, Fatiha  and Foster, George  and Kuhn, Roland  and Simard, Michel  and Joanis, Eric  and Larkin, Samuel},
  year         = 2006,
  month        = jun,
  booktitle    = {Proceedings on the Workshop on Statistical Machine Translation},
  publisher    = {Association for Computational Linguistics},
  address      = {New York City},
  pages        = {134--137},
  url          = {https://aclanthology.org/W06-3118}
}
