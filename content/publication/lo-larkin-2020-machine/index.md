---
title: Machine Translation Reference-less Evaluation using YiSi-2 with Bilingual Mappings
  of Massive Multilingual Language Model
authors:
- Chi-kiu Lo
- Samuel Larkin
date: '2020-11-01'
publishDate: '2025-02-19T14:11:51.687310Z'
publication_types:
- paper-conference
publication: '*Proceedings of the Fifth Conference on Machine Translation*'
abstract: We present a study on using YiSi-2 with massive multilingual pretrained
  language models for machine translation (MT) reference-less evaluation. Aiming at
  finding better semantic representation for semantic MT evaluation, we first test
  YiSi-2 with contextual embed- dings extracted from different layers of two different
  pretrained models, multilingual BERT and XLM-RoBERTa. We also experiment with learning
  bilingual mappings that trans- form the vector subspace of the source language to
  be closer to that of the target language in the pretrained model to obtain more
  accurate cross-lingual semantic similarity representations. Our results show that
  YiSi-2â€²s correlation with human direct assessment on translation quality is greatly
  improved by replacing multilingual BERT with XLM-RoBERTa and projecting the source
  embeddings into the tar- get embedding space using a cross-lingual lin- ear projection
  (CLP) matrix learnt from a small development set.
links:
- name: URL
  url: https://aclanthology.org/2020.wmt-1.100
---
